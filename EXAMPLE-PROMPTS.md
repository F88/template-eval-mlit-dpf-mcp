# Task: MLIT Data Platform Research & Verification

あなたは MLIT Data Platform MCP Server の活用スペシャリストです。

以下の要件に従い、調査・分析タスクを自律的に遂行してください。

## タスクの目的

MCPサーバーのツール群を最大限に活用し、「調査内容」セクションに記載された調査を実行、結果を整理、分析すること。
本タスクを通じて、MCPサーバーが提供しているツール群の有効性を検証し、その利用プロセスと結果を詳細に記録すること。合わせて、LLMがMCPサーバーをどのように活用したか(ツール選択の判断、検索戦略、有効性)を使用実績として記録・分析すること。

## 調査内容

MLIT Data Platform MCP Server を利用して避難所のデータを分析する計画を立案する。

どのようなツールが存在するかを調査し、複数のツールを組みあわせることでどのような調査、分析が可能か、候補となる分析計画を複数立案する。

## 出力要件

- 出力先ディレクトリ: 実行開始日時から生成した `yyyyMMdd-HHmmss` 形式のディレクトリを新規作成し、全ファイルをそこに出力する
- ファイル内の記述言語: **日本語**
- ファイル名: 英数字・ケバブケース (e.g., `analysis-report.md`)
- 使用モデルの記録: `LOG.md` の冒頭に、本タスクの実行に使用されたAIモデルの名称（例: `Claude Opus 4.6`, `GPT-4o` 等）を記録すること
- 生データの保存: MCPツールから取得した生データは `raw-results.json` 等のファイルに保存し、分析の再現性を確保すること

## ツールリファレンス

タスクの実行前に `.github/skills/mlit-dpf-mcp-server-research/SKILL.md` を参照し、利用可能なMCPツールの一覧・用途・パラメータを確認すること。

### 検索戦略ガイド（過去の実行で得られた知見）

以下は過去の調査で有効だった検索パターンである。計画策定時の参考とすること:

1. **行政コードの事前取得**: `normalize_codes` で都道府県・市区町村コードを正確に取得してから、他ツールのパラメータに使用する
2. **段階的データ探索**: `get_suggest` → `search` → `get_data` の順で、キーワード候補の確認 → データセット特定 → 詳細属性の理解と段階的に深掘りする
3. **件数確認→一括取得**: `get_count_data` で件数を事前に確認し、管理可能な範囲であれば `get_all_data` で一括取得する。件数が多い場合は `search` + ページネーション、または空間検索で絞り込む
4. **属性検索の精度向上**: `search_by_attribute` では `attribute_name="DPF:dataset_id"` でデータセットを明示的に指定し、`term` で追加条件を付けると精度が高い
5. **空間検索の活用**: `search_by_location_point_distance` はキーワード(`term`)と組み合わせることで、特定種類の施設のみを地理的に絞り込める。異種データセット間の近接性分析に有効

### 既知の注意点

- `get_count_data` は `term` パラメータによるフィルタリングが効かない場合がある（常に全件数を返す可能性）
- `search_by_location_rectangle` は避難所以外のデータセットも混入するため、結果のフィルタリングが必要
- ツールごとにパラメータ名が微妙に異なる場合がある（例: `prefecture_code` vs `pref_code`）。エラー発生時はパラメータ名を重点的に確認する

## 実行プロセス

### 1. 事前調査（ツール・データの把握）

計画策定の前に、以下の事前調査を実施して計画の質を高めること:

- `.github/skills/mlit-dpf-mcp-server-research/SKILL.md` を読み、利用可能なMCPツールの全体像を把握する
- `get_suggest` でキーワード候補を確認し、データプラットフォーム上の用語を理解する
- `get_data_catalog_summary` でデータカタログの全体構造を把握する
- 必要に応じて `search` や `get_data` でサンプルデータを取得し、データの属性構造を理解する

この事前調査も `LOG.md` にステップとして記録すること。

### 2. 対応計画の策定 (`PLAN.md`)

事前調査の結果を踏まえ、効率的なデータ取得・分析計画を策定する。
分析の切り口（例：区ごとの数、災害種別ごとの対応可否など）もここで定義すること。

`PLAN.md` の冒頭には以下のメタ情報を記載すること:

```markdown
# 対応計画: (調査タイトル)

- 実行日時: YYYY-MM-DD HH:MM JST
- 使用モデル: (本タスクの実行に使用されたAIモデルの名称)
```

### 3. 計画の実行と検証ログの記録 (`LOG.md`)

計画に基づきツールを実行し、データを取得・分析する。

`LOG.md` の冒頭には以下のメタ情報を記載すること:

```markdown
# 実行ログ: (調査タイトル)

- 実行日時: YYYY-MM-DD HH:MM JST
- 使用モデル: (本タスクの実行に使用されたAIモデルの名称)
```

**ツールを1回実行するごとに**、以下のフォーマットで `LOG.md` に追記すること。まとめて後から書くのではなく、実行の都度記録する。

```markdown
### ステップ N: (実行内容の要約)

- **タイムスタンプ**: HH:MM～HH:MM (所要時間: X分)
- **目的**: 何を知りたくて実行したか
- **使用ツール**: ツール名と主要パラメータ
- **結果**: 実行結果の概要(成功/失敗、取得件数、主要なデータ項目など)
- **考察・次手**: 結果を受けてどう判断したか、次に何をするか
```

#### エラー発生時の対応

想定と異なる結果やエラーが発生した場合は、以下の手順でリカバリすること:

1. エラーの内容と原因を `LOG.md` に記録する
2. パラメータ名の誤りが疑われる場合は、SKILL.md を再確認してパラメータを修正する
3. ツール自体の制約が原因の場合は、代替ツールまたは代替パラメータでの再試行を検討する
4. リカバリの結果も含めて `LOG.md` に記録する（エラーと解決を対にして記録）

#### 実行時間記録

全ステップ完了後、以下の形式で実行時間サマリーを記録すること:

```markdown
## 実行時間サマリー

| ステップ | 実行時刻 | 所要時間 |
|---------|--------|--------|
| Step 1 | 17:08～17:09 | 1分 |
| Step 2 | 17:09～17:10 | 1分 |
| ... | ... | ... |
| **計** | **17:08～17:XX** | **XX分** |
```

### 4. 分析レポートの作成

取得したデータを基に、PLAN.md で定義した成果物一覧に従って分析レポートを作成する。
各レポートには以下を含めること。

- データの出典（使用したデータセットID等）
- データから読み取れる傾向や洞察
- 必要に応じて表やリストによるデータの整理

### 5. LLM 実行統計の記録

全ステップ完了後、`LOG.md` に以下の実行統計をセクションとして追加すること:

```markdown
## LLM 実行統計

### 実行概要

| 項目 | 数値 |
|-----|------|
| 総ステップ数 | X ステップ |
| MCP ツール呼び出し数 | X 回 |
| 総実行時間 | X 分 |
| 生成ファイル数 | X 個 |
| 生成総行数 | X 行 |

### ツール呼び出し成功率

| 項目 | 数値 |
|-----|------|
| 成功 | X 回 |
| パラメータ誤りによるエラー | X 回 |
| ツール側エラー | X 回 |
| リトライ | X 回 |
| 成功率 | X% (X/X) |

### トークン消費（参考値）

APIレスポンスやシステムメトリクスからトークン情報が取得可能な場合のみ記載する。
正確な値が不明な場合は、このサブセクションを「正確な値が取得できないため省略」と記載して省略すること。
```

### 6. MCPサーバー使用実績の記録

全ステップ完了後、`LOG.md` に以下のMCPサーバー使用実績をセクションとして追加すること。
ステップ1～Nの実行記録を振り返り、使用したツールの情報を集計・整理する。

#### 6.1 使用ツール一覧

各ツールについて、呼び出し回数・カテゴリ・利用目的を一覧化する。

```markdown
## MCPサーバー使用実績

### 使用ツール一覧

| ツール名 | 呼び出し回数 | カテゴリ | 利用目的 |
|---------|------------|---------|--------|
| `normalize_codes` | X回 | ユーティリティ | (このツールを何のために使ったか) |
| `search` | X回 | 検索 | (このツールを何のために使ったか) |
| `search_by_location_rectangle` | X回 | 空間検索 | (このツールを何のために使ったか) |
| `get_data` | X回 | データ取得 | (このツールを何のために使ったか) |
| ... | ... | ... | ... |
| **合計** | **XX回** | **X種** | |
```

#### 6.2 ツール有効性の評価

各ツール(パラメータの組み合わせが異なる場合は別行とする)について、有効性を「高/中/低」で評価し、その理由を記録する。

```markdown
### ツール有効性の評価

| ツール名 | 有効性 | 評価理由 |
|---------|-------|--------|
| `normalize_codes` | 高 | (評価の理由) |
| `search` (phrase_match=false) | 低 | (評価の理由) |
| `search_by_location_rectangle` | 高 | (評価の理由) |
| ... | ... | ... |
```

#### 6.3 カテゴリ別集計

ツールをカテゴリ(ユーティリティ/検索系/データ取得系/カタログ参照 等)で分類し、それぞれの呼び出し回数と成功率を集計する。

```markdown
### カテゴリ別集計

| カテゴリ | ツール種数 | 呼び出し回数 | 成功率 |
|---------|----------|------------|-------|
| ユーティリティ | X種 | X回 | X% (X/X) |
| 検索系 | X種 | X回 | X% (X/X) |
| データ取得系 | X種 | X回 | X% (X/X) |
| **合計** | **X種** | **XX回** | **X% (X/X)** |
```

#### 6.4 検索戦略の知見

本調査を通じて得られた検索戦略に関する知見を箇条書きで記録する。以下のような観点を含めること:

- どのツール・パラメータの組み合わせが最も有効だったか
- キーワード検索と空間検索の使い分けに関する知見
- 期待通りに動作しなかったツールや検索条件とその理由
- 今後の類似調査で推奨される検索アプローチ
